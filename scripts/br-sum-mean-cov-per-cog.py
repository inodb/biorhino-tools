#!/usr/bin/env python
"""
Calculates expression per COG per sample. Outputs a tsv with COG expression in
each sample. The number of columns is equal to 4 + n where n is the number of
samples. The header looks as follows

cog_hit\tcog_description\tcog_class\tcog_class_description\thist_mean_sum_n

Parses output from
    - a gff generated by Prodigal
        prodigal -a proteins.aa.fa -d genes.nuc.fa -i assembly.fa -f gff -p meta > prodigal.gff
    - protein translations from Prodigal
        proteins.aa.fa (see prodigal command for prodigal.gff)
    - webMGA output.2 file for COG functional annotation on proteins.aa.fa
    - histogram files for each sample generated with
        bedtools coverage -hist samplen.bam prodigal.gff > samplen.gff.coverage.hist
"""
import pandas
import argparse
import sys

def standardize_columns_names(df):
    """Replace - with _, ' ' with _ and change to lowercase for more easy
    column selection with df.example_example"""
    df.rename(columns=dict([(k, k.replace('-', '_').replace(' ', '_').lower())
                            for k in df.columns]), inplace=True)

def main(gfffile, proteinsfa, wmgaoutput2, samplehists, samplenames):
    # get gff
    gff = pandas.read_csv(gfffile, sep='\t',
                          comment='#', skiprows=3,
                          names=('seqname', 'source', 'feature', 'start',
                                 'end', 'score', 'strand', 'frame', 'group'),
                          header=None).dropna(how='all').reset_index(drop=True)

    # get group data
    make_series = lambda x: pandas.Series([v[1] for v in
                                           [r.split('=') for r in
                                            x.split(';')[:-1]]],
                                          index=["group_" + v[0] for v in
                                                 [r.split('=') for r in
                                                  x.split(';')[:-1]]])
    groupdata = gff['group'].apply(make_series)

    # concat
    gffbig = pandas.concat([gff, groupdata], axis=1, join_axes=[gff.index])
    standardize_columns_names(gffbig)

    # get protein ids to group id mappings
    with open(proteinsfa) as fh:
        protein_gff_table = []

        for line in fh:
            if line.startswith('>'):
                splits = line.split()
                protein_id = splits[0][1:]
                groupinfo = splits[-1]
                gff_id = groupinfo.split(';')[0].split('=')[1]
                protein_gff_table.append([gff_id, protein_id])
    protein_gff_df = pandas.DataFrame(protein_gff_table, columns=['group_id', 'protein_id'])

    # merge dataframes
    gffbigprot = pandas.merge(gffbig, protein_gff_df)

    # find best scoring COG hits for each protein from webmga
    cog = pandas.read_csv(wmgaoutput2, sep='\t')
    cog.columns = ["cog_" + c for c in cog.columns]
    cog.rename(columns={'cog_#Query': 'protein_id'}, inplace=True)
    standardize_columns_names(cog)
    cogmax = cog.groupby('protein_id').apply(lambda t: t[t['cog_score'] == t['cog_score'].max()])

    # merge dataframes
    gffbigprotcog = pandas.merge(gffbigprot, cogmax)

    # detemine mean coverage for each feature using bedtools coverage histogram
    # output
    allmerged = gffbigprotcog
    for i, h in enumerate(samplehists):
        gffhist = pandas.read_csv(h, sep='\t',
                                  names=('seqname', 'source', 'feature',
                                         'start', 'end', 'score', 'strand',
                                         'frame', 'group', 'hist_cov',
                                         'hist_nr_bases', 'hist_length',
                                         'hist_ratio'),
                                  usecols=['group', 'hist_cov', 'hist_ratio'],
                                  header=None).dropna(how='all').reset_index(drop=True)
        groupdatahist = gffhist['group'].apply(make_series)
        gffbighist = pandas.concat([gffhist, groupdatahist], axis=1, join_axes=[gffhist.index])
        standardize_columns_names(gffbighist)
        gffbighistmean = gffbighist.groupby('group_id').apply(lambda t: sum(t['hist_cov'] * t['hist_ratio']))
        colname = 'hist_mean_' + samplenames[i]
        gffbighistmean.name = colname
        allmergedtemp = allmerged.join(gffbighistmean, on='group_id', how='left')
        allmerged = allmergedtemp
        col_zerofilled = allmerged[colname].fillna(0)
        allmerged[colname] = col_zerofilled

    calc_sum_means = lambda t: \
        pandas.Series([t["cog_description"][t["cog_description"].index[0]],
                       t["cog_class"][t["cog_class"].index[0]],
                       t["cog_class_description"][t["cog_class_description"].index[0]]]
                      + [sum(t['hist_mean_' + s]) for s in
                         samplenames],
                      index=["cog_description", "cog_class",
                             "cog_class_description"] + ['hist_mean_sum_' +
                                                         s for s in
                                                         samplenames])

    cogmeans = allmerged.groupby('cog_hit').apply(calc_sum_means)
    cogmeans.to_csv(sys.stdout, sep="\t")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__,
                                     formatter_class=
                                     argparse.RawDescriptionHelpFormatter)
    parser.add_argument("gff", help="gff file generated by e.g."
                        "Prodigal 2.60")
    parser.add_argument("proteinsfa", help="protein translations generated"
                        "by e.g. Prodigal 2.60")
    parser.add_argument("wmgaoutput2", help="WebMGA output.2 file for COG"
                        "annotation of proteinsfa")
    parser.add_argument("samplehist", nargs="+", help="bedtools"
                        "coverage generated file one for each sample")
    parser.add_argument("--samplenames", default=None, help="File with sample "
                        "names, one line each. Should be same nr as"
                        "sample.coverage.hist.")
    args = parser.parse_args()

    # Get sample names
    if args.samplenames is not None:
        samplenames = [s[:-1] for s in open(args.samplenames).readlines()]
        if len(samplenames) != len(args.samplehist):
            raise(Exception("Nr of names in samplenames should be equal to nr "
                            "of given samplehists"))

    main(args.gff, args.proteinsfa, args.wmgaoutput2, args.samplehist, samplenames)
